# DeepEMD: Differentiable **Earth Mover’s Distance** for Few-Shot Learning

# 用于小样本学习的**推土机距离**

本文是2020年5月8号发表在CVPR上的一篇小样本学习（few-shot learning）方向的文章，[文章链接](https://arxiv.org/abs/2003.06777v1 )、[代码链接](https://github.com/icoz69/DeepEMD) 。

本文提出了一种基于度量学习的小样本学习算法（**DeepEMD**），将一张图片拆分成多个图块(一张图片的局部)，然后引入一种新的距离度量方式--**Earth Mover's Distance**（**EMD** 推土机距离），**EMD**其实就是线性规划中运输问题的最优解；通过线性规划的方式寻找两张图片各个图块间的最佳匹配方式，为不同位置的图块赋予不同的权重，从而表示两张图片间的相似度。



### 线性规划中的运输问题

货源地(产地)**O={$s_i|i=1,...,m$​​​}**          $o_i$​​​​：货源地**i**的供货量

目的地(销地)**D={$d_i|i=1,...,k$}**          $d_j$​：目的地**j**的需求量

$c_{i,j}$​​：**i**和**j**两地的单位运输成本

$x_{i,j}$​：**i**和**j**两地的运输量

目标问题：寻找总运输成本最低的运输方案$\tilde{X}={\tilde{x_{i,j}|i=1,...,m;j=1,...,k}}$
$$
\min_{x_{i,j}}=\sum_{i=1}^m\sum_{j=1}^k c_{i,j}x_{i,j}
$$
**subject to**
$$
x_{i,j}\geqslant0 \quad\quad i=1,...,m;j=1,...,k \\
	\sum_{j=1}^k x_{i,j}=o_i \quad\quad i=1,...,m \\
	\sum_{j=i}^k x_{i,j}=d_j \quad\quad j=1,...,k
$$
**例子：**

|      运输成本      | **销地$D_1$​** | **销地**$D_2$​ | **销地**$D_2$​ | **产量（供货量）** |
| :----------------: | :-----------: | :-----------: | :-----------: | :----------------: |
|   **产地$O_1$​​**    | **6**$x_{11}$ | **4**$x_{12}$ | **6**$x_{13}$ |      **200**       |
|   **产地$O_2$​​**    | **6**$x_{21}$ | **5**$x_{22}$ | **5**$x_{23}$ |      **300**       |
| **销量（需求量）** |    **150**    |    **150**    |    **200**    |                    |

**最小化总运输成本：**

​		
$$
\min f =6x_{11}+4x_{12}+6x_{13}+6x_{21}+5x_{22}+5x_{23}
$$
**suject to**
$$
x_{i,j}\geqslant0 \quad\quad i=1,2;j=1,2,3  \\
x_{11}+x_{12}+x_{13} \leqslant 200  \\
x_{21}+x_{22}+x_{23} \leqslant 300  \\
x_{11}+x_{21} \leqslant 150  \\
x_{12}+x_{22} \leqslant 150  \\
x_{13}+x_{23} \leqslant 200  \\
$$

### EMD for Few-shot Classification

**局部特征表示**可能提供跨类别的可迁移信息，将一张图像分解成**一组局部特征表示**，并通过**cross-reference mechanism（交差参考机制）**为两幅图像中**局部特征表示**分配适当的权值，使用他们之间的最优匹配代价来表示两张图像的差异。

#### 本文提出**三种方法**来产生图像的**局部特征表示**：

1. Fully convolutional Network（DeepEMD-FCN）

   ​	一张图片的特征表示$U\in R^{H\times W\times C}$                 **一组局部特征表示集合** $U=[u_1,u_2,...,u_{HW}]$

   这里的$u_i\quad i=1,...,HW$​当做集合中的节点   ​  

   ​	这里的**节点**其实就是之前看过一篇论文中的**局部描述子**（local descriptor）的概念，表示一张图片中的一个局部块。

2. Dividing the input image into grids（DeepEMD-Grid）

   ​	先将image划分成$H\times W$个区域，再将每个区域分别送入到卷积神经网络中

3. Random sampling image patches（DeepEMD-Sampling）

   ​	在图片中随机取样M个patches（具有不同长宽和纵横比），再将这些patches缩放到相同的输入大小，输入到神经网络中

   

得到局部特征表示后，通过两个图像局部特征表示的节点$u_i和v_j$得到这两个节点之间的差异$c_{i,j}$（也就是线性规划中的单位运输成本$c_{i,j}$）
$$
c_{i,j} = 1 - \frac{u_i^Tv_j}{||u_i|||v_j||}   \\
\frac{u_i^Tv_j}{||u_i|||v_j||} \quad 就是两个节点之间的相似度 所用相似度度量为余弦距离
$$


#### cross-reference mechanism（交差参考机制）

这里将一张**query image**的**所有局部特征向量**当成**所有的货源地**，一张**suppor image**的**所有局部特征向量**当成**所有的目的地**

$u_i$ 和 $v_j$ 分别代表query image和support image的**局部特征表示**，这里的 $o_i$（**产量**）表示query image中的**局部特征向量**$u_i$和support image中的**所有局部特征向量**的相关性评分，作为权重值(也就是 $o_i$​​ ​的产量)：
$$
o_i=\max \{u_i^T\ \frac{\sum_{j=1}^{HW}v_j}{HW} , 0\}
$$
​	max()函数保证非负



**对权值进行标准化**：
$$
\hat{o_i}=o_i \frac{HW}{\sum_{j=1}^{HW} o_j}
$$
这里其实可以直接写作（也就是每个产地的产量除以所以产地的产量，做一个标准化）：
$$
\begin{aligned}
\hat{o_i} &= o_i \frac{HW}{\sum_{j=1}^{HW} o_j} \\
  &=\max \{u_i^T\ \frac{\sum_{j=1}^{HW}v_j}{HW} , 0\}  \frac{HW}{\sum_{j=1}^{HW} o_j} \\
  &=u_i^T\ \frac{\sum_{j=1}^{HW}v_j}{HW}\frac{HW}{\sum_{j=1}^{HW} o_j} \\
  &=u_i^T\frac{\sum_{j=1}^{HW}v_j}{\sum_{j=1}^{HW} o_j}
 \end{aligned}
$$
同理：可以计算出**需求量**$d_j$​

### 代码调试

pytorch的快速可微qp求解器[qpth英文介绍](https://locuslab.github.io/qpth/)

快速可微求解模块**'qpth**'

```python
pip install qpth   //安装'qpth'模块
```

凸优化求解模块'**cvxpy**'

```python
pip install cvxpy  //安装'cvxpy'模块
```



![image-20210828154649811](https://gitee.com/lin2000h/images/raw/master/image-20210828154649811.png)

这里的进度条**'300/300'**指的是预训练时，一共是**64个类别**的图片，每个类别有**600**张图片；则预训练总的图片为**64*600=38400**张图片需要进行监督学习。这里预训练设置的**batch_size=128**，那么总的**batch_num=38400/128=300**。

### 个人总结

#### 2021-8-2

今天争取看完预训练的所有代码，目前阶段来看所提出的EMD距离就是将之前的分类问题转化为一个数学建模中的线性规划的一个运输问题。然后其中所提出的局部特征表示（一张图片中的节点），在目前自己所掌握的知识来看，就是之前论文中所提出的局部描述子的概念（local descriptor），也就是空间注意力。这里认为一张图片的特征向量和另一张图片的特征向量进行对比，效果不理想（会有背景等因素的干扰）；将一张图片的局部描述子和另一张图片的局部描述子进行相关性评分，赋予局部描述子以不同的权重。

#### 2021-8-3

关于**data_shot**取前五个数据是来自五个不同类别的解释：

```python
    # 这里的k=5*1  五个类别 每个类别一张图片  
    data_shot, data_query = data[:k], data[k:]
```

```python
    
    # batch = torch.stack(batch).t().reshape(-1)

    # 这里的batch是5个数组 每个数组里面放着同一类别的16个索引 也就是一个类别的16张图片
    batch_s = torch.stack(batch)  # 首先将5个放索引的数组进行拼接 [5, 16]
    batch_t = batch_s.t()  # 转置一下 [16,5]
    # 这样就变成16个数组  每个数组里面放着5个不同的类别的一个索引
    batch = batch_t.reshape(-1)  
```

![image-20210828154702863](https://gitee.com/lin2000h/images/raw/master/image-20210828154702863.png)

这里显示**gpu**内存不足，服务器train不起来

#### 2021-8-4

代码部分除了meta_train.py因为gpu内存不足跑不起来，其他都看完了；当然三种方法提取局部特征这里只看了最基本的fcn。

大致总结一下，就是将求解两张图片（query image和support image）相似度问题转化为一个线性规划的运输问题；对于运输问题中的**产量P**和**需求量O**（以产量P为例，query image的每一个局部特征表示和support image中所有的局部特征表示**点乘**得到一个相似度评分，作为产量，需求量同理）；对于运输问题中的**运输成本 $c_{i,j}$** 就是将两张图片的每一个局部特征表示做一个余弦相似度度量，通过公式（5）得到**运输成本 $c_{i,j}$** 。其实上述都做了相似度度量，一个是直接点乘一个是用了余弦距离。

最后用所提供的的**cv2.EMD()**进行求解，这个大致的过程不清楚，应该就是求解线性规划中的运输问题；因为我们这里有的**所有产地的产量P**和**所有销地的销量D**，以及每个产地到每个销地的单位运输成本 $c_{i,j}$​ ，最后就是通过 **每个产地到每个销地的运输量 $x_{i,j}$​​** 求解最低运输成本。当然，我们这里求解的是两张图片的相似度，这里刚好取反加负号求解的就是最大化相似度问题。



#### 2021-8-6

这里注意**miniimagenet**数据集的图片尺寸**都不是84\*84**， 每张图片经过**RandomResizedCrop(84)**和**RandomHorizontalFlip()**（图片尺寸84*84随机裁剪，以及随机水平翻转），再输入**embedding**的图片尺寸都是**84\*84**。

**DeepEMD-Sampling**：就是**每张图片**经过随机裁剪以及水平翻转后得到**M张**相同大小的**84\*84**尺寸的图片，然后输入搭配**embedding**中。

这里**M=16**（M=25服务器跑步起来了，计算量比较大），相当于**每张图片**先随机裁剪、水平翻转后将图片尺寸变为**84\*84**，这样处理**16次**得到**16张随机取样的图片**；然后经过**embedding**得到**16个节点**（类比于上面的fcn局部特征表示，相当于这样处理一张图片，所获取的图片信息更多；而**fcn**只是一张图片经过embedding，然后对embedding之后的图片进行处理；也就是空间注意力，embedding后的图片尺寸为5\*5，这样就可以得到25个个节点）
